import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# ðŸ†• å¼•å…¥é…ç½®æ–‡ä»¶
from config import Config

def load_price_data(csv_path: str) -> pd.DataFrame:
    # ... (ä¿æŒä½ åŽŸæœ‰çš„åŠ è½½ä»£ç ä¸å˜ï¼Œéžå¸¸å®Œç¾Ž) ...
    # 1. åˆæ¬¡å°è¯•è¯»å–
    try:
        df = pd.read_csv(csv_path, low_memory=False)
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return pd.DataFrame()

    if len(df) > 0 and ("http" in str(df.columns[0]) or "www" in str(df.columns[0])):
        df = pd.read_csv(csv_path, skiprows=1, low_memory=False)

    df.columns = [c.strip().lower() for c in df.columns]
    
    if "timestamp" in df.columns:
        df["time"] = pd.to_datetime(df["timestamp"])
    elif "unix" in df.columns:
        df["unix"] = pd.to_numeric(df["unix"], errors='coerce')
        max_ts = df["unix"].max()
        if pd.isna(max_ts) or max_ts == 0:
            return pd.DataFrame()
        if max_ts > 1e14: unit = 'us'
        elif max_ts > 1e11: unit = 'ms'
        else: unit = 's'
        df["time"] = pd.to_datetime(df["unix"], unit=unit)
    elif "date" in df.columns:
         df["time"] = pd.to_datetime(df["date"])
    else:
        return pd.DataFrame() 

    df = df.set_index("time").sort_index()
    df = df[df.index > pd.to_datetime("2010-01-01")]
    
    required_cols = ["open", "high", "low", "close"]
    for col in required_cols:
        if col not in df.columns:
            raise ValueError(f"æ–‡ä»¶ {csv_path} ç¼ºå°‘åˆ—: {col}")
    if "volume" not in df.columns and "vol" in df.columns:
        df["volume"] = df["vol"]

    df["ret"] = df["close"].pct_change().fillna(0)
    return df

def calculate_scaled_forecast(df: pd.DataFrame) -> pd.DataFrame:
    """
    ðŸ”¥ æ ¸å¿ƒå‡çº§: åŸºäºŽ Config å‚æ•°çš„ EWMAC (å‡çº¿äº¤å‰) ç­–ç•¥
    
    é€»è¾‘é“¾æ¡:
    1. è®¡ç®—æ³¢åŠ¨çŽ‡ (åˆ†æ¯)
    2. è®¡ç®— 4 ç»„å‡çº¿äº¤å‰ (åˆ†å­)
    3. ä¹˜ä»¥å¯¹åº”çš„ Scalar (ç¼©æ”¾)
    4. åŠ æƒå¹³å‡ (é›†æˆ)
    """
    data = df.copy()
    
    # ==========================================
    # ðŸ§  æ­¥éª¤ A: è®¡ç®—æ³¢åŠ¨çŽ‡ (Standard Deviation)
    # ==========================================
    # ä½¿ç”¨ Config ä¸­çš„çª—å£ (é€šå¸¸æ˜¯ 36)
    # ç‰©ç†æ„ä¹‰ï¼šé£Žé™©æ ‡å°ºã€‚
    vol_span = Config.VOL_LOOKBACK
    data['volatility'] = data['close'].ewm(span=vol_span).std()
    
    # é˜²é™¤é›¶ä¿æŠ¤ (åŠ ä¸Šä¸€ä¸ªæžå°å€¼)
    data['volatility'] = data['volatility'].replace(0, np.nan).fillna(method='ffill') + 1e-8
    
    # ==========================================
    # âš¡ æ­¥éª¤ B: å¾ªçŽ¯è®¡ç®— 4 ä¸ªå­ç­–ç•¥
    # ==========================================
    fast_spans = Config.STRATEGY_PARAMS['fast_span']
    slow_spans = Config.STRATEGY_PARAMS['slow_span']
    scalars = Config.STRATEGY_PARAMS['scalars']
    weights = Config.WEIGHTS
    
    # ç”¨äºŽå­˜å‚¨å„å­ç­–ç•¥çš„"æ ‡å‡†åŒ– Forecast"
    forecast_cols = []
    
    print(f"ðŸ”„ æ­£åœ¨è®¡ç®— {len(fast_spans)} ç»„ EWMAC ç­–ç•¥...")
    
    for i in range(len(fast_spans)):
        fast = fast_spans[i]
        slow = slow_spans[i]
        scalar = scalars[i]
        
        # 1. è®¡ç®—å¿«æ…¢å‡çº¿
        ema_fast = data['close'].ewm(span=fast).mean()
        ema_slow = data['close'].ewm(span=slow).mean()
        
        # 2. åŽŸå§‹äº¤å‰å€¼ (Raw Cross) = å¿«çº¿ - æ…¢çº¿
        raw_cross = ema_fast - ema_slow
        
        # 3. æ ‡å‡†åŒ–é¢„æµ‹ (Scaled Forecast)
        # å…¬å¼: (å¿« - æ…¢) * Scalar / æ³¢åŠ¨çŽ‡
        # å«ä¹‰: å½“å‰çš„å‡çº¿å·®å€¼ï¼Œç›¸å½“äºŽå¤šå°‘å€çš„æ—¥æ³¢åŠ¨çŽ‡ï¼Ÿ
        col_name = f'fc_{fast}_{slow}'
        data[col_name] = (raw_cross * scalar) / data['volatility']
        
        forecast_cols.append(col_name)
        # print(f"   âœ… ç­–ç•¥ {fast}/{slow}: Scalar={scalar}")

    # ==========================================
    # âš–ï¸ æ­¥éª¤ C: é›†æˆ (Ensemble)
    # ==========================================
    # åŠ æƒå¹³å‡
    # è¿™é‡Œçš„ weights éƒ½åœ¨ Config é‡Œ (0.25, 0.25, 0.25, 0.25)
    combined_forecast = data[forecast_cols].mul(weights).sum(axis=1)
    
    # ==========================================
    # ðŸ›¡ï¸ æ­¥éª¤ D: å°é¡¶ (Capping)
    # ==========================================
    # Carver å»ºè®®å•ä¸ªç­–ç•¥é€šå¸¸é™åˆ¶åœ¨ +/- 20 ä¹‹é—´
    data['forecast'] = combined_forecast.clip(lower=-20.0, upper=20.0).fillna(0)
    
    # è®°å½•ä¸€äº›è°ƒè¯•ä¿¡æ¯
    data['ema_slow_base'] = data['close'].ewm(span=slow_spans[-1]).mean() # ç”»å›¾ç”¨æœ€æ…¢çš„çº¿
    
    return data

# ... (run_vectorized_backtest å’Œ calculate_position_target ä¿æŒä¸å˜) ...
def run_vectorized_backtest(df:pd.DataFrame,fee_rate=0.0005)->pd.DataFrame:
    # ä¿æŒåŽŸæ ·
    data=df.copy()
    data["market_log_ret"]=np.log(data['close']).diff().fillna(0)
    data['strategy_log_ret']=data['position']*data['market_log_ret']
    position_change=data['position'].diff().abs().fillna(0)
    data['cost']=position_change*fee_rate
    data['net_log_ret']=data['strategy_log_ret']-data['cost']
    data['equity'] = np.exp(data['net_log_ret'].cumsum())
    data['buy_hold_equity']=np.exp(data['market_log_ret'].cumsum())
    return data

def calculate_position_target(df:pd.DataFrame,forecast_col='forecast',buffer=0.1)->pd.DataFrame:
    # ä¿æŒåŽŸæ · (è¿™ä¸ªå‡½æ•°éžå¸¸ç»å…¸ï¼Œä¸éœ€è¦æ”¹)
    data=df.copy()
    # 1. æ˜ å°„: -20/+20 -> -1.0/+1.0 (æ»¡ä»“)
    # è¿™ä¸€æ­¥å·²ç»éšå«äº† Volatility Targeting çš„éƒ¨åˆ†é€»è¾‘(æ»¡ä»“é™åˆ¶)
    # åŽç»­ Phase 4 æˆ‘ä»¬ä¼šåœ¨è¿™é‡Œå¼•å…¥æ›´ä¸¥æ ¼çš„ Target Risk è®¡ç®—
    ideal_position=data[forecast_col]/20.0 # æ³¨æ„ï¼šè¿™é‡Œå¦‚æžœ forecast æ»¡æ ¼æ˜¯20ï¼Œé™¤ä»¥20å½’ä¸€åŒ–
    ideal_position=ideal_position.clip(lower=-1.0,upper=1.0)

    ideal_values=ideal_position.values
    n=len(ideal_values)
    buffered_position=np.zeros(n)
    current_pos=0.0

    for i in range(n):
        ideal=ideal_values[i]
        if abs(ideal-current_pos)>buffer:
            current_pos=ideal
        else: current_pos = current_pos
        buffered_position[i]=current_pos
        
    data['raw_target']=ideal_position 
    data['buffered_pos']=buffered_position 
    data['position']=data['buffered_pos'].shift(1).fillna(0)
    return data